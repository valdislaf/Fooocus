volumes:
  fooocus-data:

services:
  app:
    build: .
    image: ghcr.io/lllyasviel/fooocus
    ports:
      - "7865:7865"
    user: "0:0"
    environment:
      - CMDARGS=--listen        # Arguments for launch.py.
      - DATADIR=/content/data   # Directory which stores models, outputs dir
      - config_path=/content/data/config.txt
      - config_example_path=/content/data/config_modification_tutorial.txt
      - path_checkpoints=/content/data/models/checkpoints/
      - path_loras=/content/data/models/loras/
      - path_embeddings=/content/data/models/embeddings/
      - path_vae_approx=/content/data/models/vae_approx/
      - path_upscale_models=/content/data/models/upscale_models/
      - path_inpaint=/content/data/models/inpaint/
      - path_controlnet=/content/data/models/controlnet/
      - path_clip_vision=/content/data/models/clip_vision/
      - path_fooocus_expansion=/content/data/models/prompt_expansion/fooocus_expansion/
      # Outputs directory INSIDE container (we mount it to Windows path below)
      - path_outputs=/content/win_outputs/
      - XFORMERS=0
      - DTYPES=fp16
    volumes:
      # Keep models/cache inside a named Docker volume (fast, not on C:)
      - fooocus-data:/content/data
      # Windows outputs bind-mount example:
      # Change F:/fooocus_outputs to any directory on your system where you want images saved
      - F:\fooocus_outputs:/content/win_outputs
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [compute, utility]
